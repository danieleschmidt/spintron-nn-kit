#!/usr/bin/env python3
"""
Minimal Framework Validation - Dependency-Free Testing.

This script validates the framework without external dependencies
to ensure basic structure and functionality work correctly.
"""

import sys
import os
import importlib.util
import traceback
import time
import json
from pathlib import Path

def test_framework_structure():
    """Test basic framework structure."""
    print("üìÅ Testing Framework Structure...")
    
    required_files = [
        "spintron_nn/__init__.py",
        "spintron_nn/core/__init__.py",
        "spintron_nn/research/__init__.py", 
        "spintron_nn/reliability/__init__.py",
        "spintron_nn/security/__init__.py",
        "spintron_nn/scaling/__init__.py"
    ]
    
    missing = []
    for file_path in required_files:
        if not Path(file_path).exists():
            missing.append(file_path)
            print(f"‚ùå Missing: {file_path}")
        else:
            print(f"‚úÖ Found: {file_path}")
    
    success = len(missing) == 0
    print(f"Structure validation: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    return success

def test_basic_imports():
    """Test basic imports without heavy dependencies."""
    print("\nüêç Testing Basic Module Imports...")
    
    # Test import structure without numpy/torch dependencies
    test_imports = [
        "spintron_nn",
        "spintron_nn.core",
        "spintron_nn.research", 
        "spintron_nn.reliability",
        "spintron_nn.security",
        "spintron_nn.scaling"
    ]
    
    success = True
    for module_name in test_imports:
        try:
            # Use importlib to avoid loading numpy/torch dependencies
            spec = importlib.util.find_spec(module_name)
            if spec is None:
                print(f"‚ùå Module not found: {module_name}")
                success = False
            else:
                print(f"‚úÖ Module found: {module_name}")
        except Exception as e:
            print(f"‚ùå Import error for {module_name}: {str(e)}")
            success = False
    
    print(f"Import validation: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    return success

def test_file_content_validity():
    """Test that key files have valid Python syntax."""
    print("\nüìù Testing File Content Validity...")
    
    key_files = [
        "spintron_nn/__init__.py",
        "spintron_nn/core/mtj_models.py",
        "spintron_nn/core/crossbar.py",
        "spintron_nn/research/algorithms.py",
        "spintron_nn/reliability/fault_tolerance.py",
        "spintron_nn/security/secure_computing.py"
    ]
    
    success = True
    for file_path in key_files:
        if not Path(file_path).exists():
            continue
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Basic syntax validation
            compile(content, file_path, 'exec')
            print(f"‚úÖ Valid syntax: {file_path}")
            
        except SyntaxError as e:
            print(f"‚ùå Syntax error in {file_path}: {e}")
            success = False
        except Exception as e:
            print(f"‚ùå Error reading {file_path}: {e}")
            success = False
    
    print(f"Syntax validation: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    return success

def test_dependency_free_functionality():
    """Test functionality that doesn't require numpy/torch."""
    print("\n‚öôÔ∏è Testing Dependency-Free Functionality...")
    
    test_code = '''
# Test basic configuration classes
class MockConfig:
    def __init__(self, **kwargs):
        for key, value in kwargs.items():
            setattr(self, key, value)

# Test data structures
config = MockConfig(
    resistance_high=10000,
    resistance_low=5000, 
    switching_voltage=0.3
)

assert config.resistance_high == 10000
assert config.resistance_low == 5000
assert config.switching_voltage == 0.3

# Test basic calculations
def calculate_conductance(resistance):
    if resistance <= 0:
        raise ValueError("Resistance must be positive")
    return 1.0 / resistance

conductance_high = calculate_conductance(config.resistance_high)
conductance_low = calculate_conductance(config.resistance_low)

assert 0 < conductance_high < conductance_low
assert abs(conductance_high - 1e-4) < 1e-6

# Test basic data validation
def validate_voltage(voltage):
    if not isinstance(voltage, (int, float)):
        raise TypeError("Voltage must be numeric")
    if voltage < 0 or voltage > 10:
        raise ValueError("Voltage out of range")
    return True

assert validate_voltage(config.switching_voltage)
assert validate_voltage(0.0)
assert validate_voltage(5.0)

try:
    validate_voltage(-1)
    assert False, "Should have raised ValueError"
except ValueError:
    pass

try:
    validate_voltage("invalid")
    assert False, "Should have raised TypeError"  
except TypeError:
    pass

print("‚úÖ All dependency-free tests passed")
'''
    
    try:
        # Safe execution of validation code in controlled environment
        # Using compile and exec with restricted globals for security
        compiled_code = compile(test_code, '<validation_test>', 'exec')
        test_globals = {
            '__builtins__': {
                'print': print,
                'assert': assert,
                'len': len,
                'range': range,
                'sum': sum,
                'max': max,
                'min': min,
                'abs': abs,
                'round': round,
                'TypeError': TypeError,
                'ValueError': ValueError,
                'True': True,
                'False': False
            }
        }
        exec(compiled_code, test_globals)
        print("‚úÖ Dependency-free functionality: PASSED")
        return True
    except Exception as e:
        print(f"‚ùå Dependency-free functionality: FAILED - {e}")
        traceback.print_exc()
        return False

def test_configuration_files():
    """Test configuration files are valid."""
    print("\nüìÑ Testing Configuration Files...")
    
    success = True
    
    # Test pyproject.toml
    try:
        import tomllib
        with open('pyproject.toml', 'rb') as f:
            pyproject_data = tomllib.load(f)
        
        # Check required fields
        assert 'project' in pyproject_data
        assert 'name' in pyproject_data['project']
        assert pyproject_data['project']['name'] == 'spintron-nn-kit'
        
        print("‚úÖ pyproject.toml is valid")
        
    except ImportError:
        # Python < 3.11, try basic file read
        try:
            with open('pyproject.toml', 'r') as f:
                content = f.read()
            assert 'spintron-nn-kit' in content
            print("‚úÖ pyproject.toml exists and contains project name")
        except Exception as e:
            print(f"‚ùå pyproject.toml error: {e}")
            success = False
    except Exception as e:
        print(f"‚ùå pyproject.toml validation failed: {e}")
        success = False
    
    # Test package.json
    try:
        with open('package.json', 'r') as f:
            package_data = json.load(f)
        
        assert 'name' in package_data
        assert package_data['name'] == 'spintron-nn-kit'
        assert 'scripts' in package_data
        
        print("‚úÖ package.json is valid")
        
    except Exception as e:
        print(f"‚ùå package.json validation failed: {e}")
        success = False
    
    print(f"Configuration validation: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    return success

def test_documentation_completeness():
    """Test documentation files exist and have content."""
    print("\nüìö Testing Documentation...")
    
    required_docs = [
        ("README.md", 1000),  # At least 1000 characters
        ("pyproject.toml", 100),
        ("package.json", 100)
    ]
    
    success = True
    for doc_file, min_size in required_docs:
        try:
            if not Path(doc_file).exists():
                print(f"‚ùå Missing documentation: {doc_file}")
                success = False
                continue
                
            file_size = Path(doc_file).stat().st_size
            if file_size < min_size:
                print(f"‚ùå Documentation too short: {doc_file} ({file_size} < {min_size} bytes)")
                success = False
            else:
                print(f"‚úÖ Documentation adequate: {doc_file} ({file_size} bytes)")
                
        except Exception as e:
            print(f"‚ùå Error checking {doc_file}: {e}")
            success = False
    
    print(f"Documentation validation: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    return success

def main():
    """Run minimal validation tests."""
    print("üöÄ SPINTRONIC NEURAL NETWORK FRAMEWORK - MINIMAL VALIDATION")
    print("=" * 70)
    print("Running dependency-free validation tests...")
    print()
    
    start_time = time.time()
    
    # Run all tests
    test_results = []
    test_results.append(("Framework Structure", test_framework_structure()))
    test_results.append(("Basic Imports", test_basic_imports()))
    test_results.append(("File Content Validity", test_file_content_validity()))
    test_results.append(("Dependency-Free Functionality", test_dependency_free_functionality()))
    test_results.append(("Configuration Files", test_configuration_files()))
    test_results.append(("Documentation", test_documentation_completeness()))
    
    execution_time = time.time() - start_time
    
    # Summary
    passed_tests = sum(1 for _, result in test_results if result)
    total_tests = len(test_results)
    success_rate = (passed_tests / total_tests) * 100
    
    print("\n" + "=" * 70)
    print("üìä MINIMAL VALIDATION SUMMARY")
    print("=" * 70)
    
    overall_success = passed_tests == total_tests
    
    if overall_success:
        print("üéâ ALL MINIMAL VALIDATION TESTS PASSED!")
        status_emoji = "‚úÖ"
    else:
        print("‚ùå SOME VALIDATION TESTS FAILED")
        status_emoji = "‚ùå"
    
    print(f"\n{status_emoji} Overall Success: {overall_success}")
    print(f"üìà Success Rate: {success_rate:.1f}%")
    print(f"‚úÖ Passed Tests: {passed_tests}/{total_tests}")
    print(f"‚è±Ô∏è Execution Time: {execution_time:.2f} seconds")
    
    print("\nüìã DETAILED RESULTS:")
    for test_name, result in test_results:
        status = "‚úÖ" if result else "‚ùå"
        print(f"  {status} {test_name}")
    
    if overall_success:
        print("\nüéØ READY FOR DEPENDENCY INSTALLATION")
        print("  ‚Ä¢ Basic framework structure is valid")
        print("  ‚Ä¢ All modules have correct syntax")
        print("  ‚Ä¢ Configuration files are properly formatted")
        print("  ‚Ä¢ Documentation is present and adequate")
        print("\n  Next steps:")
        print("  1. Install dependencies: pip install -e .")
        print("  2. Run full quality gates: python3 run_quality_gates.py")
    else:
        print("\n‚ö†Ô∏è ISSUES DETECTED")
        print("  ‚Ä¢ Address validation failures before proceeding")
        print("  ‚Ä¢ Check file syntax and structure")
        print("  ‚Ä¢ Ensure all required files are present")
    
    # Save minimal validation report
    report = {
        "timestamp": time.time(),
        "overall_success": overall_success,
        "success_rate": success_rate,
        "passed_tests": passed_tests,
        "total_tests": total_tests,
        "execution_time": execution_time,
        "test_results": [{"test": name, "passed": result} for name, result in test_results]
    }
    
    with open("minimal_validation_report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    print(f"\nüìÑ Report saved to: minimal_validation_report.json")
    
    return 0 if overall_success else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)